TITLE: HoloGAN: Unsupervised Learning of 3D Representation From Natural Images
URL: https://arxiv.org/abs/1904.01326

OUR MINIMUM GOALS:

QUALITATIVE EVALUATION: Figure 4. For the Chairs dataset with high intra-class variation,
HoloGAN can still disentangle pose (360° azimuth, 160° elevation) and identity.

QUANTITATIVE EVALUATION: Table 1. The HoloGAN result just for the Chairs dataset. (Row:4-Col:2)
Table 1. KID between real images and images generated by HoloGAN and other 2D-based GANs (lower
is better). The table shows that HoloGAN can achieve a competitive or higher KID score with other
methods, while providing explicit control of objects in the generated images (not measured by KID).

NOTE: We have not been able to reach the Chairs dataset yet. But we sent a request. In the worst
case, we plan to just switch the dataset with the CelebA for the same evaluation (Figure 5 and
Table 1 again). We do not prefer the CelebA dataset directly because the authors made some
preprocessing on this dataset and do not explain the preprocess exactly.

—— version 1 submission ——
We reached and downloaded the Chairs dataset but it was closed-box (i.e. including all types of
furniture). Extracting only chairs looks more complicated than using directly the CelebA dataset.
Thus, we found the CelebA dataset more accessible and switched it.

This change does not affect our goals because both goal table and figure includes the both datasets
with the same configuration. As we mentioned, the preprocessing steps are not explained in the
paper. However, we found the steps in their GitHub repo as their Tensorflow code. We followed these
preprocessing steps in our implementation. The processed input images used in their code and our
project are compared. We have seen and confirmed that both are the same.

Our samples and KID scores (specified in our goals) can be found in the main.ipynb
