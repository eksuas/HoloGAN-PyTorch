{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CENG796 Term Project\n",
    "\n",
    "## HoloGAN: Unsupervised Learning of 3D Representations from Natural Images\n",
    "\n",
    "Our term project is to re-implementation of the HoloGAN: Unsupervised Learning of 3D Representations from Natural Images study (can be found at https://arxiv.org/abs/1904.01326). The source codes, license, dataset downloader script can be found in [the GitHub repo](https://github.com/eksuas/HoloGAN-PyTorch).\n",
    "\n",
    "\n",
    "### Abstract of the paper\n",
    "\n",
    "We propose a novel generative adversarial network (GAN) for the task of unsupervised learning of 3D representations from natural images. Most generative models rely on 2D kernels to generate images and make few assumptions about the 3D world. These models therefore tend to create blurry images or artefacts in tasks that require a strong 3D understanding, such as novel-view synthesis. HoloGAN instead learns a 3D representation of the world, and to render this representation in a realistic manner. Unlike other GANs, HoloGAN provides explicit control over the pose of generated objects through rigid-body transformations of the learnt 3D features. Our experiments show that using explicit 3D features enables HoloGAN to disentangle 3D pose and identity, which is further decomposed into shape and appearance, while still being able to generate images with similar or higher visual quality than other generative models. HoloGAN can be trained end-to-end from unlabelled 2D images only. Particularly, we do not require pose labels, 3D shapes, or multiple views of the same objects. This shows that HoloGAN is the first generative model that learns 3D representations from natural images in an entirely unsupervised manner.\n",
    "\n",
    "### Group members of the project\n",
    "\n",
    "Edanur Demir and Gökhan Özsarı\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters\n",
    "\n",
    "These are the hyper-parameters of our model:\n",
    "\n",
    "```\n",
    "  --seed N              random seed\n",
    "  --image-path S        training dataset directory path (default: '../dataset/celebA/')\n",
    "  --dataset {celebA}    dataset selection (default: celebA)\n",
    "  --gpu                 flag to enable cuda computation (default: False)\n",
    "  --batch-size N        training batch size of the model (default: 32)\n",
    "  --max-epochs N        the maximum number of epochs for training (default: 50)\n",
    "  --epoch-step N        epoch step to compute the adaptive learning rate (default: 25)\n",
    "  --z-dim N             the length of the generative model input (default: 128)\n",
    "  --d-lr N              the learning rate of the discriminator (default: 0.0001)\n",
    "  --g-lr N              the learning rate of the generator (default: 0.0001)\n",
    "  --beta1 N             minimum betas parameter of the Adam optimizer (default: 0.5)\n",
    "  --beta2 N             maximum betas parameter of the Adam optimizer (default: 0.999)\n",
    "  --lambda-latent N     the lambda latent coefficient given in the paper (default: 0.0)\n",
    "  --elevation-low N     the minimum elevation angle (default: 70)\n",
    "  --elevation-high N    the maximum elevation angle (default: 110)\n",
    "  --azimuth-low N       the minimum azimuth angle (default: 220)\n",
    "  --azimuth-high N      the maximum azimuth angle (default: 320)\n",
    "  --scale-low N         the minimum scaling value of 3D transformation (default: 1.0)\n",
    "  --scale-high N        the maximum scaling value of 3D transformation (default: 1.0)\n",
    "  --transX-low N        the minimum translation factor across the X-axis (default: 0)\n",
    "  --transX-high N       the maximum translation factor across the X-axis (default: 0)\n",
    "  --transY-low N        the minimum translation factor across the Y-axis (default: 0)\n",
    "  --transY-high N       the maximum translation factor across the Y-axis (default: 0)\n",
    "  --transZ-low N        the minimum translation factor across the Z-axis (default: 0)\n",
    "  --transZ-high N       the maximum translation factor across the Z-axis (default: 0)\n",
    "  --log-interval N      logging interval in terms of batch size (default: 1000)\n",
    "  --update-g-every-d N  do not save the current model\n",
    "  --no-save-model       flag to not save the current model (default: False)\n",
    "  --rotate-elevation    flag to rotate the z sampling with elevation (default: False)\n",
    "  --rotate-azimuth      flag to rotate the z sampling with azimuth (default: False)\n",
    "  --load-dis S          the path for loading and/or evaluating the discriminator\n",
    "  --load-gen S          the path for loading and/or evaluating the generator\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model\n",
    "\n",
    "We can create an instance of the HoloGAN by giving the arguments as a parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broken training is detected. Starting epoch is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\py35\\lib\\site-packages\\torch\\serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\py35\\lib\\site-packages\\torch\\serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LeakyReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\py35\\lib\\site-packages\\torch\\serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.instancenorm.InstanceNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\py35\\lib\\site-packages\\torch\\serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\py35\\lib\\site-packages\\torch\\serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Sigmoid' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\py35\\lib\\site-packages\\torch\\serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\py35\\lib\\site-packages\\torch\\serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\py35\\lib\\site-packages\\torch\\serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.conv.ConvTranspose3d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\py35\\lib\\site-packages\\torch\\serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.conv.ConvTranspose2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from init import initializer\n",
    "from hologan import HoloGAN\n",
    "\n",
    "sys.argv = [\"\", \"--max-epochs\", \"3\"]\n",
    "args = initializer()\n",
    "model = HoloGAN(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "HoloGAN has its own train function as below. During training, it updates the parameters of the Discriminator at each batch one time. But, the Generator is updated two times at each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [  0/  2] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-32e39578b798>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\CENGs\\CENG 796\\HoloGAN-PyTorch\\hologan.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"epoch\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m             \u001b[1;31m# validate and keep history at each log interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\CENGs\\CENG 796\\HoloGAN-PyTorch\\hologan.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(self, args, epoch)\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mview_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m             \u001b[0md_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"d\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"g\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\CENGs\\CENG 796\\HoloGAN-PyTorch\\hologan.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(self, x, z, view_in, args, batch_id)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mq_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_z_pred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_id\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_g_every_d\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mgen_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlambda_latent\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mq_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hologan\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hologan\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(self, args):\n",
    "    \"\"\"HoloGAN trainer\n",
    "\n",
    "    This method train the HoloGAN model.\n",
    "    \"\"\"\n",
    "    d_lr = args.d_lr\n",
    "    g_lr = args.g_lr\n",
    "    for epoch in range(args.start_epoch, args.max_epochs):\n",
    "        # Adaptive learning rate\n",
    "        if epoch >= args.epoch_step:\n",
    "            adaptive_lr = (args.max_epochs - epoch) / (args.max_epochs - args.epoch_step)\n",
    "            d_lr *= adaptive_lr\n",
    "            g_lr *= adaptive_lr\n",
    "            for param_group in self.optimizer_discriminator.param_groups:\n",
    "                param_group['lr'] = d_lr\n",
    "            for param_group in self.optimizer_generator.param_groups:\n",
    "                param_group['lr'] = g_lr\n",
    "\n",
    "        result = collections.OrderedDict({\"epoch\":epoch})\n",
    "        result.update(self.train_epoch(args, epoch))\n",
    "        # validate and keep history at each log interval\n",
    "        self.save_history(args, result)\n",
    "\n",
    "    # save the model giving the best validation results as a final model\n",
    "    if not args.no_save_model:\n",
    "        self.save_model(args, args.max_epochs-1, best=True)\n",
    "        \n",
    "model.train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading\n",
    "\n",
    "We can load a pre-trained model as below. \n",
    "\n",
    "and computing qualitative samples/outputs from that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples are saved in samples\\celebA\\sample_1590314062.147041\\samples_220.png\n",
      "Samples are saved in samples\\celebA\\sample_1590314062.147041\\samples_230.png\n",
      "Samples are saved in samples\\celebA\\sample_1590314062.147041\\samples_240.png\n",
      "Samples are saved in samples\\celebA\\sample_1590314062.147041\\samples_250.png\n",
      "Samples are saved in samples\\celebA\\sample_1590314062.147041\\samples_260.png\n",
      "Samples are saved in samples\\celebA\\sample_1590314062.147041\\samples_270.png\n",
      "Samples are saved in samples\\celebA\\sample_1590314062.147041\\samples_280.png\n",
      "Samples are saved in samples\\celebA\\sample_1590314062.147041\\samples_290.png\n",
      "Samples are saved in samples\\celebA\\sample_1590314062.147041\\samples_300.png\n",
      "Samples are saved in samples\\celebA\\sample_1590314062.147041\\samples_310.png\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from init import initializer\n",
    "from hologan import HoloGAN\n",
    "\n",
    "sys.argv = [\"\", \"--rotate-azimuth\", \"--gpu\", \"--batch-size\", \"1\",\n",
    "            \"--load-dis\", \"models/model_final/discriminator.pt\",\n",
    "            \"--load-gen\", \"models/model_final/generator.pt\"]\n",
    "args = initializer()\n",
    "model = HoloGAN(args)\n",
    "model.sample(args, trained=True, collection=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "reproducing the result(s) in the form of plots and/or tables, as you've declared that you have declared. Please add a brief explanation / pointer to the paper so that a reader can understand what these results are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A section describing the challenges (if any) that you have encountered when implementing the paper. This should primarily include implementation details that you could not find in the paper, the assumptions made that you had to make (eg. number of layers).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Requirements for Version 1:***\n",
    "\n",
    "* Each project should accompany a Jupyter Notebook file that contains sections for: The Jupyter notebook should come with pre-computed outputs. This is to show your results without having to re-run your notebook.\n",
    "\n",
    "* A bash script called download_data.sh that downloads any necessary data (datasets, pre-trained models, etc.) that you could not include in your ODTUclass submission due to file size.\n",
    "\n",
    "* License.txt containing MIT License.\n",
    "\n",
    "* These requirements are mostly trivial and/or come from the original definition of the project but if any one of them creates a big overhead for your version-1 submissions, please contact us with a specific reason why it is not feasible to satisfy within a few days. If there is a special case applying to your project, we may give you an exemption for version-1 submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
